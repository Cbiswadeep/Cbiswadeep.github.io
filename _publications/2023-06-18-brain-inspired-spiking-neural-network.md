---
title: "Brain-Inspired Spiking Neural Network for Online Unsupervised Time Series Prediction"
collection: publications
permalink: /publication/2023-06-18-brain-inspired-spiking-neural-network
excerpt: 'Introducing the Continuous Learning-based Unsupervised Recurrent Spiking Neural Network Model (CLURSNN), this paper tackles the challenge of energy and data-efficient online time series prediction in evolving dynamical systems, crucial for edge AI applications. Unlike traditional DNN-based models requiring extensive data and continuous retraining, CLURSNN leverages spike-timing dependent plasticity (STDP) for online predictions, adapting to changes in the underlying system efficiently and without the need for retraining.'
date: 2023
venue: '2023 International Joint Conference on Neural Networks (IJCNN)'
pages: '1-8'
publisher: 'IEEE'
citation: 'Biswadeep Chakraborty, Saibal Mukhopadhyay. (2023). "Brain-Inspired Spiking Neural Network for Online Unsupervised Time Series Prediction." 2023 International Joint Conference on Neural Networks (IJCNN), IEEE, pp. 1-8.'
---

In the realm of edge AI applications, the capability for online time series prediction—adapting continuously to streaming data and evolving dynamical systems—is paramount. Traditional Deep Neural Network (DNN)-based supervised learning models, while powerful, often fall short in such scenarios. They typically demand large volumes of training data and suffer from an inability to swiftly adapt to systemic changes without undergoing continuous retraining, rendering them inefficient for real-time applications.

Addressing these critical limitations, our work introduces the Continuous Learning-based Unsupervised Recurrent Spiking Neural Network Model (CLURSNN). By employing a novel training approach rooted in spike-timing dependent plasticity (STDP), CLURSNN is designed to make online predictions that accurately reconstruct the underlying dynamical system. This is achieved through Random Delay Embedding, which measures the membrane potential of neurons within the recurrent layer, allowing for real-time adjustments to new data without the need for extensive retraining.

This innovative approach not only significantly enhances the efficiency and adaptability of online time series prediction models but also aligns closely with the energy-efficient computational paradigms observed in biological neural systems. Through the development of CLURSNN, we aim to pave the way for more robust, adaptable, and biologically plausible models in the field of edge computing and beyond, contributing to the advancement of autonomous AI systems capable of continuous learning and adaptation.
